{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ef4df8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def load_file(filepath):\n",
    "    dataframe = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
    "    return dataframe.values\n",
    "\n",
    "\n",
    "# load a list of files and return as a 3d numpy array\n",
    "def load_group(filenames, prefix=''):\n",
    "    loaded = list()\n",
    "    for name in filenames:\n",
    "        data = load_file(prefix + name)\n",
    "        loaded.append(data)\n",
    "    # stack group so that features are the 3rd dimension\n",
    "    loaded = np.dstack(loaded)\n",
    "    return loaded\n",
    "\n",
    "# load a dataset group, such as train or test\n",
    "def load_dataset_group(group, prefix=''):\n",
    "    filepath = prefix + group + '/Inertial Signals/'\n",
    "    # load all 9 files as a single array\n",
    "    filenames = list()\n",
    "    # total acceleration\n",
    "    filenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
    "    # body acceleration\n",
    "    filenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
    "    # body gyroscope\n",
    "    #filenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
    "    # load input data\n",
    "    X = load_group(filenames, filepath)\n",
    "    # load class output\n",
    "    y = load_file(prefix + group + '/y_'+group+'.txt')\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# load the dataset, returns train and test X and y elements\n",
    "def load_dataset(prefix=''):\n",
    "    # load all train\n",
    "    trainX, trainy = load_dataset_group('train', prefix + 'F:/HAR/UCI/')\n",
    "    # load all test\n",
    "    testX, testy = load_dataset_group('test', prefix + 'F:/HAR/UCI/')\n",
    "    \n",
    "    #zero-offset class values\n",
    "    trainy = trainy - 1\n",
    "    testy = testy - 1\n",
    "    #one hot encode y\n",
    "    trainy_one_hot = to_categorical(trainy)\n",
    "    testy_one_hot = to_categorical(testy)\n",
    "    print(trainX.shape, trainy.shape, trainy_one_hot.shape, testX.shape, testy.shape, testy_one_hot.shape)\n",
    "    return trainX, trainy, trainy_one_hot, testX, testy, testy_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eecc9361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 128, 6) (7352, 1) (7352, 6) (2947, 128, 6) (2947, 1) (2947, 6)\n"
     ]
    }
   ],
   "source": [
    "trainX, trainy, trainy_one_hot, testX, testy, testy_one_hot = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ea4cc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape:  (7352, 128, 6)\n",
      "Y train shape:  (7352, 1)\n",
      "Y train One hot shape:  (7352, 6)\n",
      "X test shape:  (2947, 128, 6)\n",
      "Y test shape:  (2947, 1)\n",
      "Y test One hot shape:  (2947, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"X train shape: \", trainX.shape)\n",
    "print(\"Y train shape: \", trainy.shape)\n",
    "print(\"Y train One hot shape: \", trainy_one_hot.shape)\n",
    "print(\"X test shape: \", testX.shape)\n",
    "print(\"Y test shape: \", testy.shape)\n",
    "print(\"Y test One hot shape: \", testy_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0beb04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Walking: 1226\n",
      "1: WU: 1073\n",
      "2: WD: 986\n",
      "3: Sitting: 1286\n",
      "4: Standing: 1374\n",
      "5: Standing: 1374\n",
      "6: Laying: 1407\n"
     ]
    }
   ],
   "source": [
    "print(\"0: Walking:\" ,np.where(trainy == 0)[0].size)\n",
    "print(\"1: WU:\" ,np.where(trainy == 1)[0].size)\n",
    "print(\"2: WD:\" ,np.where(trainy == 2)[0].size)\n",
    "print(\"3: Sitting:\" ,np.where(trainy == 3)[0].size)\n",
    "print(\"4: Standing:\" ,np.where(trainy == 4)[0].size)\n",
    "print(\"5: Standing:\" ,np.where(trainy == 4)[0].size)\n",
    "print(\"6: Laying:\" ,np.where(trainy == 5)[0].size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06e3dd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data label statistics::\n",
      "[[   0 1226]\n",
      " [   1 1073]\n",
      " [   2  986]\n",
      " [   3 1286]\n",
      " [   4 1374]\n",
      " [   5 1407]]\n",
      "Test data label statistics::\n",
      "[[  0 496]\n",
      " [  1 471]\n",
      " [  2 420]\n",
      " [  3 491]\n",
      " [  4 532]\n",
      " [  5 537]]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(trainy, return_counts=True)\n",
    "print (\"Train data label statistics::\")\n",
    "print (np.asarray((unique, counts)).T)  \n",
    "\n",
    "unique, counts = np.unique(testy, return_counts=True)\n",
    "print (\"Test data label statistics::\")\n",
    "print (np.asarray((unique, counts)).T)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eca75dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all = trainX   # at this stage, the data includes both dynamic and static HAR data\n",
    "y_train_all = trainy\n",
    "\n",
    "X_test_all = testX\n",
    "y_test_all = testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06856a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "static_2 = np.where(trainy  == 0)[0]\n",
    "static_3 = np.where(trainy == 1)[0]\n",
    "static_4 = np.where(trainy  == 2)[0]\n",
    "\n",
    "static = np.concatenate([static_2, static_3, static_4])\n",
    "static_list = static.tolist()\n",
    "\n",
    "# Shuffle dynamic data index\n",
    "r = random.random()\n",
    "random.shuffle(static_list, lambda: r)\n",
    "\n",
    "static = np.array(static_list)\n",
    "\n",
    "trainX = X_train_all[static]\n",
    "trainy = y_train_all[static]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2db2ae03",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_2 = np.where(testy == 0)[0]\n",
    "static_3 = np.where(testy == 1)[0]\n",
    "static_4 = np.where(testy == 2)[0]\n",
    "static = np.concatenate([static_2, static_3, static_4])\n",
    "static_list = static.tolist()\n",
    "\n",
    "r = random.random()\n",
    "random.shuffle(static_list, lambda: r)\n",
    "\n",
    "static = np.array(static_list)\n",
    "\n",
    "testX = X_test_all[static]\n",
    "testy = y_test_all[static]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92892243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 0: Walking: 496\n",
      "Train1: WU: 471\n",
      "Train2: WD: 420\n",
      "Train3: Sitting: 0\n",
      "Train4: Standing: 0\n",
      "Train5: Laying: 0\n",
      "Test 0: Walking: 1226\n",
      "Test 1: WU: 1073\n",
      "Test 2: WD: 986\n",
      "Test 3: Sitting: 0\n",
      "Test 4: Standing: 0\n",
      "Test 5: Laying: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Train 0: Walking:\" ,np.where(testy == 0)[0].size)\n",
    "print(\"Train1: WU:\" ,np.where(testy == 1)[0].size)\n",
    "print(\"Train2: WD:\" ,np.where(testy == 2)[0].size)\n",
    "print(\"Train3: Sitting:\" ,np.where(testy == 3)[0].size)\n",
    "print(\"Train4: Standing:\" ,np.where(testy == 4)[0].size)\n",
    "print(\"Train5: Laying:\" ,np.where(testy == 5)[0].size) \n",
    "\n",
    "print(\"Test 0: Walking:\" ,np.where(trainy == 0)[0].size)\n",
    "print(\"Test 1: WU:\" ,np.where(trainy == 1)[0].size)\n",
    "print(\"Test 2: WD:\" ,np.where(trainy == 2)[0].size)\n",
    "print(\"Test 3: Sitting:\" ,np.where(trainy == 3)[0].size)\n",
    "print(\"Test 4: Standing:\" ,np.where(trainy == 4)[0].size)\n",
    "print(\"Test 5: Laying:\" ,np.where(trainy == 5)[0].size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a784275f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainy_one_hot = to_categorical(trainy)\n",
    "testy_one_hot = to_categorical(testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e33a1168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape:  (3285, 128, 6)\n",
      "Y train shape:  (3285, 1)\n",
      "Y train One hot shape:  (3285, 3)\n",
      "X test shape:  (1387, 128, 6)\n",
      "Y test shape:  (1387, 1)\n",
      "Y test One hot shape:  (1387, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"X train shape: \", trainX.shape)\n",
    "print(\"Y train shape: \", trainy.shape)\n",
    "print(\"Y train One hot shape: \", trainy_one_hot.shape)\n",
    "print(\"X test shape: \", testX.shape)\n",
    "print(\"Y test shape: \", testy.shape)\n",
    "print(\"Y test One hot shape: \", testy_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "251e74f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data label statistics::\n",
      "[[   0 1226]\n",
      " [   1 1073]\n",
      " [   2  986]]\n",
      "Test data label statistics::\n",
      "[[  0 496]\n",
      " [  1 471]\n",
      " [  2 420]]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(trainy, return_counts=True)\n",
    "print (\"Train data label statistics::\")\n",
    "print (np.asarray((unique, counts)).T)  \n",
    "\n",
    "unique, counts = np.unique(testy, return_counts=True)\n",
    "print (\"Test data label statistics::\")\n",
    "print (np.asarray((unique, counts)).T)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96ac3ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_val,y_train_one_hot,y_val_one_hot,y_train,y_val=train_test_split(trainX, trainy_one_hot, trainy,test_size=0.2,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc2d6bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], testy_one_hot.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "804113bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 6, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_timesteps, n_features, n_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d34e001",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dense, InputLayer, Dropout, Flatten, BatchNormalization, Conv1D\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63dbf291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 6)]             0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 128, 6)]             0         []                            \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)        [(None, 128, 6)]             0         []                            \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)        [(None, 128, 6)]             0         []                            \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)             (None, 126, 128)             2432      ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)           (None, 124, 128)             3968      ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)           (None, 122, 128)             5504      ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)           (None, 120, 128)             7040      ['input_4[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 492, 128)             0         ['conv1d[0][0]',              \n",
      "                                                                     'conv1d_1[0][0]',            \n",
      "                                                                     'conv1d_2[0][0]',            \n",
      "                                                                     'conv1d_3[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1  (None, 98, 128)              0         ['concatenate[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)           (None, 96, 64)               24640     ['max_pooling1d[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)           (None, 94, 64)               41024     ['max_pooling1d[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)           (None, 92, 64)               57408     ['max_pooling1d[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)           (None, 90, 64)               73792     ['max_pooling1d[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 372, 64)              0         ['conv1d_4[0][0]',            \n",
      " )                                                                   'conv1d_5[0][0]',            \n",
      "                                                                     'conv1d_6[0][0]',            \n",
      "                                                                     'conv1d_7[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPoolin  (None, 74, 64)               0         ['concatenate_1[0][0]']       \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)           (None, 72, 32)               6176      ['max_pooling1d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)           (None, 70, 32)               10272     ['max_pooling1d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)          (None, 68, 32)               14368     ['max_pooling1d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)          (None, 66, 32)               18464     ['max_pooling1d_1[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 276, 32)              0         ['conv1d_8[0][0]',            \n",
      " )                                                                   'conv1d_9[0][0]',            \n",
      "                                                                     'conv1d_10[0][0]',           \n",
      "                                                                     'conv1d_11[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPoolin  (None, 55, 32)               0         ['concatenate_2[0][0]']       \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 1760)                 0         ['max_pooling1d_2[0][0]']     \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 512)                  901632    ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 3)                    1539      ['dense[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1168259 (4.46 MB)\n",
      "Trainable params: 1168259 (4.46 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##Level_1\n",
    "# layer 1\n",
    "inputs1_1= Input(shape=(n_timesteps,n_features))##128,9\n",
    "conv1_1 = Conv1D(filters=128, kernel_size=3, activation='relu')(inputs1_1) ##none,126,128\n",
    "# layer 2\n",
    "inputs1_2= Input(shape=(n_timesteps,n_features))\n",
    "conv1_2 = Conv1D(filters=128, kernel_size=5, activation='relu')(inputs1_2)##124,128\n",
    "# layer 3\n",
    "inputs1_3= Input(shape=(n_timesteps,n_features))\n",
    "conv1_3 = Conv1D(filters=128, kernel_size=7, activation='relu')(inputs1_3)##122,128\n",
    "# layer 4\n",
    "inputs1_4= Input(shape=(n_timesteps,n_features))\n",
    "conv1_4 = Conv1D(filters=128, kernel_size=9, activation='relu')(inputs1_4)##120,128\n",
    "\n",
    "# merge1\n",
    "merged_1 = concatenate([conv1_1,conv1_2,conv1_3,conv1_4],axis=1)\n",
    "\n",
    "#maxpool1\n",
    "pool_1=MaxPooling1D(pool_size=5)(merged_1)\n",
    "\n",
    "##Level_2\n",
    "# layer 1\n",
    "conv2_1 = Conv1D(filters=64, kernel_size=3, activation='relu')(pool_1)\n",
    "# layer 2\n",
    "conv2_2 = Conv1D(filters=64, kernel_size=5, activation='relu')(pool_1)\n",
    "# layer 3\n",
    "conv2_3 = Conv1D(filters=64, kernel_size=7, activation='relu')(pool_1)\n",
    "# layer 4\n",
    "\n",
    "conv2_4 = Conv1D(filters=64, kernel_size=9, activation='relu')(pool_1) \n",
    "# merge2\n",
    "merged_2 = concatenate([conv2_1,conv2_2,conv2_3,conv2_4],axis=1)\n",
    "\n",
    "#maxpool2\n",
    "pool_2=MaxPooling1D(pool_size=5)(merged_2)\n",
    "\n",
    "\n",
    "##Level_3\n",
    "# layer 1\n",
    "conv3_1 = Conv1D(filters=32, kernel_size=3, activation='relu')(pool_2)\n",
    "# layer 2\n",
    "conv3_2 = Conv1D(filters=32, kernel_size=5, activation='relu')(pool_2)\n",
    "# layer 3\n",
    "conv3_3 = Conv1D(filters=32, kernel_size=7, activation='relu')(pool_2)\n",
    "# layer 4\n",
    "\n",
    "conv3_4 = Conv1D(filters=32, kernel_size=9, activation='relu')(pool_2) \n",
    "# merge2\n",
    "merged_3 = concatenate([conv3_1,conv3_2,conv3_3,conv3_4],axis=1)\n",
    "\n",
    "#maxpool2\n",
    "pool_3=MaxPooling1D(pool_size=5)(merged_3)\n",
    "\n",
    "\n",
    "#flatten\n",
    "flat_cnn=Flatten()(pool_3)\n",
    "\n",
    "##dense layer\n",
    "dense = Dense(512, activation='relu')(flat_cnn)\n",
    "outputs = Dense(n_outputs, activation='softmax')(dense)\n",
    "\n",
    "##MODEL\n",
    "cnn3_model = Model([inputs1_1, inputs1_2, inputs1_3,inputs1_4], outputs)\n",
    "\n",
    "cnn3_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "cnn3_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8904ba0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "83/83 [==============================] - 13s 135ms/step - loss: 0.4700 - accuracy: 0.7968 - val_loss: 0.3058 - val_accuracy: 0.8976\n",
      "Epoch 2/30\n",
      "83/83 [==============================] - 11s 129ms/step - loss: 0.0313 - accuracy: 0.9912 - val_loss: 0.2031 - val_accuracy: 0.9438\n",
      "Epoch 3/30\n",
      "83/83 [==============================] - 11s 134ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.2186 - val_accuracy: 0.9596\n",
      "Epoch 4/30\n",
      "83/83 [==============================] - 11s 128ms/step - loss: 7.5882e-04 - accuracy: 1.0000 - val_loss: 0.2873 - val_accuracy: 0.9560\n",
      "Epoch 5/30\n",
      "83/83 [==============================] - 11s 130ms/step - loss: 2.7428e-04 - accuracy: 1.0000 - val_loss: 0.2789 - val_accuracy: 0.9596\n",
      "Epoch 6/30\n",
      "83/83 [==============================] - 13s 151ms/step - loss: 1.4129e-04 - accuracy: 1.0000 - val_loss: 0.2753 - val_accuracy: 0.9589\n",
      "Epoch 7/30\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 1.0072e-04 - accuracy: 1.0000 - val_loss: 0.2959 - val_accuracy: 0.9611\n",
      "Epoch 8/30\n",
      "83/83 [==============================] - 11s 138ms/step - loss: 6.9371e-05 - accuracy: 1.0000 - val_loss: 0.3251 - val_accuracy: 0.9596\n",
      "Epoch 9/30\n",
      "83/83 [==============================] - 12s 146ms/step - loss: 5.0605e-05 - accuracy: 1.0000 - val_loss: 0.3167 - val_accuracy: 0.9589\n",
      "Epoch 10/30\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 3.6556e-05 - accuracy: 1.0000 - val_loss: 0.3256 - val_accuracy: 0.9589\n",
      "Epoch 11/30\n",
      "83/83 [==============================] - 12s 140ms/step - loss: 2.6365e-05 - accuracy: 1.0000 - val_loss: 0.3329 - val_accuracy: 0.9632\n",
      "Epoch 12/30\n",
      "83/83 [==============================] - 12s 148ms/step - loss: 1.8079e-05 - accuracy: 1.0000 - val_loss: 0.3579 - val_accuracy: 0.9632\n",
      "Epoch 13/30\n",
      "83/83 [==============================] - 12s 142ms/step - loss: 1.3079e-05 - accuracy: 1.0000 - val_loss: 0.3566 - val_accuracy: 0.9632\n",
      "Epoch 14/30\n",
      "83/83 [==============================] - 12s 143ms/step - loss: 9.5916e-06 - accuracy: 1.0000 - val_loss: 0.3783 - val_accuracy: 0.9632\n",
      "Epoch 15/30\n",
      "83/83 [==============================] - 12s 144ms/step - loss: 8.1175e-06 - accuracy: 1.0000 - val_loss: 0.3709 - val_accuracy: 0.9632\n",
      "Epoch 16/30\n",
      "83/83 [==============================] - 11s 128ms/step - loss: 5.9799e-06 - accuracy: 1.0000 - val_loss: 0.3936 - val_accuracy: 0.9632\n",
      "Epoch 17/30\n",
      "83/83 [==============================] - 11s 132ms/step - loss: 4.9574e-06 - accuracy: 1.0000 - val_loss: 0.3850 - val_accuracy: 0.9632\n",
      "Epoch 18/30\n",
      "83/83 [==============================] - 11s 127ms/step - loss: 4.1000e-06 - accuracy: 1.0000 - val_loss: 0.3991 - val_accuracy: 0.9632\n",
      "Epoch 19/30\n",
      "83/83 [==============================] - 11s 129ms/step - loss: 3.4302e-06 - accuracy: 1.0000 - val_loss: 0.3985 - val_accuracy: 0.9632\n",
      "Epoch 20/30\n",
      "83/83 [==============================] - 11s 132ms/step - loss: 2.8950e-06 - accuracy: 1.0000 - val_loss: 0.4078 - val_accuracy: 0.9632\n",
      "Epoch 21/30\n",
      "83/83 [==============================] - 12s 140ms/step - loss: 2.4599e-06 - accuracy: 1.0000 - val_loss: 0.4130 - val_accuracy: 0.9632\n",
      "Epoch 22/30\n",
      "83/83 [==============================] - 12s 140ms/step - loss: 2.1487e-06 - accuracy: 1.0000 - val_loss: 0.4167 - val_accuracy: 0.9632\n",
      "Epoch 23/30\n",
      "83/83 [==============================] - 12s 141ms/step - loss: 2.0078e-06 - accuracy: 1.0000 - val_loss: 0.4200 - val_accuracy: 0.9632\n",
      "Epoch 24/30\n",
      "83/83 [==============================] - 12s 139ms/step - loss: 1.7216e-06 - accuracy: 1.0000 - val_loss: 0.4170 - val_accuracy: 0.9632\n",
      "Epoch 25/30\n",
      "81/83 [============================>.] - ETA: 0s - loss: 1.4603e-06 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "# fit network\n",
    "model_history=cnn3_model.fit(x=[X_train,X_train,X_train,X_train], y=y_train_one_hot, epochs=30, batch_size=32,validation_data= ([testX,testX,testX,testX],testy_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0829da4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "loss =model_history.history['loss']\n",
    "val_loss =model_history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9011897a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc =model_history.history['accuracy']\n",
    "val_acc =model_history.history['val_accuracy']\n",
    "plt.plot(epochs, acc, 'y', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17f5f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "pred=cnn3_model.predict([testX,testX,testX,testX])\n",
    "pred=np.argmax(pred, axis=-1)\n",
    "cm=confusion_matrix(testy,pred)\n",
    "print(cm)\n",
    "print(accuracy_score(testy,pred))\n",
    "print(classification_report(testy,pred))\n",
    "sns.heatmap(cm, annot=True, fmt = '.2f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
