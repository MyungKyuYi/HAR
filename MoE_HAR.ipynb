{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a3e78471-9ff9-4658-bc31-10163a95b042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "aaf86a3c-5465-4ec3-9138-1dc35bc30924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 1️⃣ 데이터 로드 및 전처리 (UCI HAR Raw Data)\n",
    "# ----------------------------\n",
    "\n",
    "def load_ucihar_data(base_path=\"E:/dataset/HAR/UCI-HAR\"):\n",
    "    def load_signals(folder, dataset):\n",
    "        signals = []\n",
    "        signal_types = [\n",
    "            \"body_acc_x\", \"body_acc_y\", \"body_acc_z\",\n",
    "            \"body_gyro_x\", \"body_gyro_y\", \"body_gyro_z\",\n",
    "            \"total_acc_x\", \"total_acc_y\", \"total_acc_z\"\n",
    "        ]\n",
    "        for signal in signal_types:\n",
    "            filename = f\"{base_path}/{dataset}/Inertial Signals/{signal}_{dataset}.txt\"\n",
    "            data = np.loadtxt(filename).reshape(-1, 128, 1)  # (samples, time_steps, channels)\n",
    "            signals.append(data)\n",
    "        return np.concatenate(signals, axis=2)  # (samples, 128, 9)\n",
    "\n",
    "    # Raw 센서 데이터 로드 (9개의 센서)\n",
    "    X_train_raw = load_signals(\"train\", \"train\")  # (train_samples, 128, 9)\n",
    "    X_test_raw = load_signals(\"test\", \"test\")  # (test_samples, 128, 9)\n",
    "\n",
    "    # Feature 데이터 (561개)\n",
    "    X_train_features = np.loadtxt(f\"{base_path}/train/X_train.txt\")\n",
    "    X_test_features = np.loadtxt(f\"{base_path}/test/X_test.txt\")\n",
    "\n",
    "    # 최종 입력 데이터 결합 (CNN & LSTM에 맞게 변형)\n",
    "    X_train = np.expand_dims(X_train_raw, axis=1)  # (samples, 1, 128, 9) → CNN 입력 형태\n",
    "    X_test = np.expand_dims(X_test_raw, axis=1)\n",
    "\n",
    "    # 레이블 데이터 로드\n",
    "    y_train = np.loadtxt(f\"{base_path}/train/y_train.txt\").astype(int) - 1\n",
    "    y_test = np.loadtxt(f\"{base_path}/test/y_test.txt\").astype(int) - 1\n",
    "\n",
    "    # Tensor 변환\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# 데이터 로드\n",
    "X_train, y_train, X_test, y_test = load_ucihar_data()\n",
    "output_dim = 6  # 6개 클래스\n",
    "epochs = 50\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fcf18d21-197e-454d-bd5c-5bc1d4b9c75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Expert(nn.Module):\n",
    "    def __init__(self, num_channels=9, hidden_dim=64, output_dim=6, num_heads=4):\n",
    "        super(Expert, self).__init__()\n",
    "\n",
    "        # CNN Layer (Feature Extraction)\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=(5, 1), stride=1, padding=(2, 0))\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=(3, 1), stride=1, padding=(1, 0))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d((2, 1))  # (batch, 64, 64, 9)\n",
    "\n",
    "        # Transformer Encoder (Global Context)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=64, nhead=num_heads, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=2)\n",
    "\n",
    "        # Fully Connected Layer\n",
    "        self.fc = nn.Linear(64, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # CNN Feature Extraction\n",
    "        x = self.relu(self.conv1(x))  # (batch, 32, 128, 9)\n",
    "        x = self.relu(self.conv2(x))  # (batch, 64, 128, 9)\n",
    "        x = self.pool(x)  # (batch, 64, 64, 9)\n",
    "\n",
    "        # CNN 출력 차원 조정 → Transformer 입력 형태 (batch, time_steps=64, features=64)\n",
    "        x = x.permute(0, 2, 3, 1).contiguous()  # (batch, 64, 9, 64) → (batch, 64, 64, 9)\n",
    "        x = x.mean(dim=2)  # (batch, 64, 64), 센서 채널 평균\n",
    "\n",
    "        # Transformer Encoder\n",
    "        x = self.transformer_encoder(x)  # (batch, 64, 64)\n",
    "\n",
    "        # Mean Pooling over Time-axis\n",
    "        x = torch.mean(x, dim=1)  # (batch, 64)\n",
    "\n",
    "        # Fully Connected Layer\n",
    "        return torch.softmax(self.fc(x), dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "98862e4d-7556-4454-bef5-ba0245a1ffc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 3️⃣ Gating Network (6개 Expert 선택)\n",
    "# ----------------------------\n",
    "\n",
    "class Gating(nn.Module):\n",
    "    def __init__(self, input_dim, num_experts):\n",
    "        super(Gating, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, 128)\n",
    "        self.layer2 = nn.Linear(128, 256)\n",
    "        self.layer3 = nn.Linear(256, 128)\n",
    "        self.layer4 = nn.Linear(128, num_experts)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = torch.relu(self.layer2(x))\n",
    "        x = torch.relu(self.layer3(x))\n",
    "        return torch.softmax(self.layer4(x), dim=1)  # Expert 가중치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3276f461-ef13-476c-b187-b77b5aacc133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 4️⃣ Mixture of Experts 모델\n",
    "# ----------------------------\n",
    "\n",
    "class MoE(nn.Module):\n",
    "    def __init__(self, experts):\n",
    "        super(MoE, self).__init__()\n",
    "        self.experts = nn.ModuleList(experts)\n",
    "        self.gating = Gating(input_dim=experts[0].fc.in_features, num_experts=len(experts))\n",
    "\n",
    "    def forward(self, x):\n",
    "        weights = self.gating(x.mean(dim=1))  # Gating Network가 Expert 가중치 결정\n",
    "        expert_outputs = torch.stack([expert(x) for expert in self.experts], dim=2)  # 모든 Expert의 출력값을 stack\n",
    "        weights = weights.unsqueeze(1).expand_as(expert_outputs)  # 가중치 형태 맞추기\n",
    "        return torch.sum(expert_outputs * weights, dim=2)  # Expert 출력 조합하여 최종 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe7a41a-6617-4120-ae37-eeae742b19eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 5️⃣ Expert 학습\n",
    "# ----------------------------\n",
    "\n",
    "experts = [Expert() for _ in range(6)]\n",
    "optimizers = [optim.Adam(expert.parameters(), lr=learning_rate) for expert in experts]\n",
    "\n",
    "for i, expert in enumerate(experts):\n",
    "    optimizer = optimizers[i]\n",
    "    mask = y_train == i\n",
    "    x_train_expert, y_train_expert = X_train[mask], y_train[mask]  \n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = expert(x_train_expert)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, y_train_expert)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91930d65-6b32-4585-956e-0329c1a05b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 6️⃣ MoE 학습\n",
    "# ----------------------------\n",
    "\n",
    "moe_model = MoE(experts)\n",
    "optimizer_moe = optim.Adam(moe_model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=32, shuffle=True)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        optimizer_moe.zero_grad()\n",
    "        outputs_moe = moe_model(batch_x)\n",
    "        loss_moe = nn.CrossEntropyLoss()(outputs_moe, batch_y)\n",
    "        loss_moe.backward()\n",
    "        optimizer_moe.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd34f60-2e1e-47d4-a900-300653eb0073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 7️⃣ 모델 평가\n",
    "# ----------------------------\n",
    "\n",
    "def evaluate(model, X, y):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        accuracy = (predicted == y).sum().item() / len(y)\n",
    "    return accuracy\n",
    "\n",
    "accuracy_experts = [evaluate(expert, X_test, y_test) for expert in experts]\n",
    "accuracy_moe = evaluate(moe_model, X_test, y_test)\n",
    "\n",
    "for i, acc in enumerate(accuracy_experts):\n",
    "    print(f\"Expert {i+1} Accuracy: {acc:.4f}\")\n",
    "print(f\"Mixture of Experts Accuracy: {accuracy_moe:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2412acc8-e622-4b66-b6ac-61ba8775f4f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2577fdb0-9dfb-4915-98fc-0017b958bfd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
