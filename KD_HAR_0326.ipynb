{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "36e6fef1-867a-44cb-9ef2-17880e856dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Handle OneHotEncoder compatibility\n",
    "encoder_args = {}\n",
    "sk_version = tuple(map(int, sklearn.__version__.split(\".\")))\n",
    "if sk_version >= (1, 2):\n",
    "    encoder_args['sparse_output'] = False\n",
    "else:\n",
    "    encoder_args['sparse'] = False\n",
    "\n",
    "# 1. Load UCI HAR dataset\n",
    "def load_ucihar_dataset(base_path='E:/dataset/HAR/UCI-HAR'):\n",
    "    input_signals = [\n",
    "        \"body_acc_x_\", \"body_acc_y_\", \"body_acc_z_\",\n",
    "        \"body_gyro_x_\", \"body_gyro_y_\", \"body_gyro_z_\",\n",
    "        \"total_acc_x_\", \"total_acc_y_\", \"total_acc_z_\"\n",
    "    ]\n",
    "\n",
    "    def read_signals(folder):\n",
    "        signals = []\n",
    "        for signal in input_signals:\n",
    "            path = os.path.join(base_path, folder, \"Inertial Signals\", signal + folder + \".txt\")\n",
    "            signals.append(np.loadtxt(path))\n",
    "        return np.transpose(np.array(signals), (1, 2, 0))\n",
    "\n",
    "    def read_labels(folder):\n",
    "        path = os.path.join(base_path, folder, \"y_\" + folder + \".txt\")\n",
    "        return np.loadtxt(path).astype(int) - 1\n",
    "\n",
    "    X_train = read_signals(\"train\")\n",
    "    y_train = read_labels(\"train\")\n",
    "    X_test = read_signals(\"test\")\n",
    "    y_test = read_labels(\"test\")\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c60f9a80-95d5-44b6-8b67-3e46d7523789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Preprocessing\n",
    "def preprocess_data(X_train, y_train, X_test, y_test):\n",
    "    num_features = X_train.shape[2]\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    X_train = scaler.fit_transform(X_train.reshape(-1, num_features)).reshape(X_train.shape)\n",
    "    X_test = scaler.transform(X_test.reshape(-1, num_features)).reshape(X_test.shape)\n",
    "\n",
    "    encoder = OneHotEncoder(**encoder_args)\n",
    "    y_train = encoder.fit_transform(y_train.reshape(-1, 1))\n",
    "    y_test = encoder.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2ac93e31-0056-4b1f-933f-91f851e6557e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "# Basic Residual Block\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm1d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.dropout1(out)\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = self.dropout2(out)\n",
    "        out += self.shortcut(x)\n",
    "        return F.relu(out)\n",
    "\n",
    "# Positional Encoding for 1D sequence\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, embed_dim, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, embed_dim)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, embed_dim, 2) * (-math.log(10000.0) / embed_dim))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # [1, max_len, embed_dim]\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):  # x: [B, T, E]\n",
    "        return x + self.pe[:, :x.size(1), :]\n",
    "\n",
    "# Transformer Block\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=True)\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(embed_dim, ff_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(ff_dim, embed_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # x: [B, T, E]\n",
    "        residual = x\n",
    "        x = self.attn(x, x, x)[0]\n",
    "        x = self.norm1(x + residual)\n",
    "\n",
    "        residual = x\n",
    "        x = self.ff(x)\n",
    "        x = self.norm2(x + residual)\n",
    "        return x\n",
    "\n",
    "# 전체 모델\n",
    "class TeacherResTrans(nn.Module):\n",
    "    def __init__(self, input_channels, seq_len, num_classes,\n",
    "                 embed_dim=128, num_layers=4, num_heads=4, ff_dim=256, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.initial_conv = nn.Conv1d(input_channels, embed_dim, kernel_size=3, padding=1)\n",
    "        self.init_norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        self.pos_encoder = PositionalEncoding(embed_dim, max_len=seq_len)\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            self.layers.append(nn.ModuleDict({\n",
    "                \"resnet\": BasicBlock(embed_dim, embed_dim, dropout=dropout),\n",
    "                \"transformer\": TransformerBlock(embed_dim, num_heads, ff_dim, dropout=dropout)\n",
    "            }))\n",
    "\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.output_norm = nn.LayerNorm(embed_dim)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(embed_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # x: [B, C, T]\n",
    "        x = self.initial_conv(x)            # [B, E, T]\n",
    "        x = x.permute(0, 2, 1)              # [B, T, E]\n",
    "        x = self.init_norm(x)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = x.permute(0, 2, 1)          # [B, E, T] → ResNet\n",
    "            x = layer[\"resnet\"](x)\n",
    "            x = x.permute(0, 2, 1)          # [B, T, E] → Transformer\n",
    "            x = self.pos_encoder(x)\n",
    "            x = layer[\"transformer\"](x)\n",
    "\n",
    "        x = x.permute(0, 2, 1)              # [B, E, T]\n",
    "        x = self.global_pool(x).squeeze(-1) # [B, E]\n",
    "        x = self.output_norm(x)\n",
    "        return self.classifier(x)           # [B, num_classes]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "93691842-31a4-4ba2-8d89-aeeb011fdbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudentNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(9, 32, 16, padding=8)\n",
    "        self.conv2 = nn.Conv1d(32, 64, 16, padding=8)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc1 = nn.Linear(64, 16)\n",
    "        self.fc2 = nn.Linear(16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.global_pool(x).squeeze(-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8032b9d6-9eea-43fb-a038-2b17b84e2fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Distillation Loss\n",
    "def distillation_loss(student_logits, teacher_logits, true_labels, T, alpha):\n",
    "    kd_loss = F.kl_div(\n",
    "        F.log_softmax(student_logits / T, dim=1),\n",
    "        F.softmax(teacher_logits / T, dim=1),\n",
    "        reduction='batchmean'\n",
    "    ) * (T * T)\n",
    "    ce_loss = F.cross_entropy(student_logits, true_labels)\n",
    "    return alpha * ce_loss + (1 - alpha) * kd_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8bdc8470-0229-44ea-97a8-f595f03ee6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Train functions\n",
    "def train(model, dataloader, optimizer, teacher=None, T=2.0, alpha=0.5):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in dataloader:\n",
    "        X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        if teacher:\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = teacher(X_batch)\n",
    "            loss = distillation_loss(outputs, teacher_outputs, y_batch.argmax(dim=1), T, alpha)\n",
    "        else:\n",
    "            loss = F.cross_entropy(outputs, y_batch.argmax(dim=1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def evaluate(model, dataloader, name=\"Model\"):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in dataloader:\n",
    "            X_batch = X_batch.to(DEVICE)\n",
    "            y_batch = y_batch.argmax(dim=1)  # Convert one-hot to label\n",
    "            outputs = model(X_batch)\n",
    "            preds = outputs.argmax(dim=1).cpu().numpy()\n",
    "            labels = y_batch.cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels)\n",
    "\n",
    "    print(f\"\\nClassification Report for {name}:\")\n",
    "    print(classification_report(all_labels, all_preds))\n",
    "\n",
    "    print(f\"\\nConfusion Matrix for {name}:\")\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(f\"Confusion Matrix: {name}\")\n",
    "    plt.show()\n",
    "\n",
    "def test_model(model, dataloader, name=\"Model\"):\n",
    "    print(f\"\\nEvaluating {name}...\")\n",
    "    evaluate(model, dataloader, name=name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "8aa244f7-7c71-4cd8-bf3d-d5faa3b628fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHE_T = 20\n",
    "EPOCHE_S = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f56cfa-83ea-491c-99ae-28deecbe2194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Teacher...\n",
      "Epoch 1/20 - Teacher\n",
      "Epoch 2/20 - Teacher\n",
      "Epoch 3/20 - Teacher\n",
      "Epoch 4/20 - Teacher\n",
      "Epoch 5/20 - Teacher\n",
      "Epoch 6/20 - Teacher\n",
      "Epoch 7/20 - Teacher\n",
      "Epoch 8/20 - Teacher\n",
      "Epoch 9/20 - Teacher\n",
      "Epoch 10/20 - Teacher\n",
      "Epoch 11/20 - Teacher\n",
      "Epoch 12/20 - Teacher\n",
      "Epoch 13/20 - Teacher\n",
      "Epoch 14/20 - Teacher\n",
      "Epoch 15/20 - Teacher\n",
      "Epoch 16/20 - Teacher\n",
      "Epoch 17/20 - Teacher\n",
      "Epoch 18/20 - Teacher\n",
      "Epoch 19/20 - Teacher\n",
      "Epoch 20/20 - Teacher\n",
      "\n",
      "Training Student (Distilled)...\n",
      "Epoch 1/40 - Student\n",
      "Epoch 2/40 - Student\n",
      "Epoch 3/40 - Student\n",
      "Epoch 4/40 - Student\n",
      "Epoch 5/40 - Student\n",
      "Epoch 6/40 - Student\n",
      "Epoch 7/40 - Student\n",
      "Epoch 8/40 - Student\n",
      "Epoch 9/40 - Student\n",
      "Epoch 10/40 - Student\n",
      "Epoch 11/40 - Student\n",
      "Epoch 12/40 - Student\n",
      "Epoch 13/40 - Student\n",
      "Epoch 14/40 - Student\n",
      "Epoch 15/40 - Student\n",
      "Epoch 16/40 - Student\n",
      "Epoch 17/40 - Student\n",
      "Epoch 18/40 - Student\n",
      "Epoch 19/40 - Student\n",
      "Epoch 20/40 - Student\n",
      "Epoch 21/40 - Student\n",
      "Epoch 22/40 - Student\n",
      "Epoch 23/40 - Student\n",
      "Epoch 24/40 - Student\n",
      "Epoch 25/40 - Student\n",
      "Epoch 26/40 - Student\n",
      "Epoch 27/40 - Student\n",
      "Epoch 28/40 - Student\n",
      "Epoch 29/40 - Student\n",
      "Epoch 30/40 - Student\n",
      "Epoch 31/40 - Student\n",
      "Epoch 32/40 - Student\n",
      "Epoch 33/40 - Student\n",
      "Epoch 34/40 - Student\n",
      "Epoch 35/40 - Student\n",
      "Epoch 36/40 - Student\n",
      "Epoch 37/40 - Student\n"
     ]
    }
   ],
   "source": [
    "# 7. Main execution\n",
    "X_train, y_train, X_test, y_test = load_ucihar_dataset()\n",
    "X_train, y_train, X_test, y_test = preprocess_data(X_train, y_train, X_test, y_test)\n",
    "\n",
    "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))\n",
    "test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "teacher = TeacherNet(num_classes=6).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(teacher.parameters(), lr=0.001)\n",
    "\n",
    "print(\"Training Teacher...\")\n",
    "for epoch in range(EPOCHE_T):\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHE_T} - Teacher\")\n",
    "    train(teacher, train_loader, optimizer)\n",
    "\n",
    "student = StudentNet(num_classes=6).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(student.parameters(), lr=0.001)\n",
    "print(\"\\nTraining Student (Distilled)...\")\n",
    "for epoch in range(EPOCHE_S):\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHE_S} - Student\")\n",
    "    train(student, train_loader, optimizer, teacher=teacher, T=2.0, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e313f5b9-9d45-4ca4-8e5f-be3a09a83a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(teacher, test_loader, \"Teacher\")\n",
    "test_model(student, test_loader, \"Student\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451fa14d-f85c-418f-938e-b1ce3fab5cd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de2b35c-061a-4f91-a7eb-4c22c50309c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
